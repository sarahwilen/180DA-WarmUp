{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "576c54ba",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3d7dee",
   "metadata": {},
   "source": [
    "### Problem 1: Color Tracking\n",
    "\n",
    "- track a monochromatic object\n",
    "- create a video stream with a bounding box surrounding it by thresholding HSV or RGB values\n",
    "\n",
    "Questions:\n",
    "- Is HSV or RGB typically better?\n",
    "- How large is the threshold range that you need to track the object?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8930adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb102865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 90  76 147]]]\n"
     ]
    }
   ],
   "source": [
    "# find HSV of my blue sticky note\n",
    "# I took a picture of the sticky note and put it into a color picjer\n",
    "\n",
    "blue = np.uint8([[[147,147,103]]])\n",
    "hsv_blue=cv.cvtColor(blue,cv.COLOR_BGR2HSV)\n",
    "print(hsv_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "543258b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m cv\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m,mask)\n\u001b[1;32m     24\u001b[0m cv\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m,res)\n\u001b[0;32m---> 27\u001b[0m k\u001b[38;5;241m=\u001b[39mcv\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m27\u001b[39m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# easier to track color in HSV space\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "    # Take each frame\n",
    "    _, frame=cap.read()\n",
    "    \n",
    "    # Convert BGR to HSV\n",
    "    hsv=cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "    \n",
    "    #define range of color in HSV\n",
    "    lower_color=np.array([90-10,50,50]) #TODO\n",
    "    upper_color=np.array([90+10,255,255]) #TODO\n",
    "    \n",
    "    #Threshold the HSV image to get only my color\n",
    "    mask = cv.inRange(hsv,lower_color, upper_color)\n",
    "    \n",
    "    #Bitwise-AND mask and original image\n",
    "    res=cv.bitwise_and(frame,frame,mask=mask)\n",
    "    \n",
    "    cv.imshow('frame',frame)\n",
    "    cv.imshow('mask',mask)\n",
    "    cv.imshow('res',res)\n",
    "    \n",
    "    \n",
    "    k=cv.waitKey(5) & 0xFF\n",
    "    if k==27:\n",
    "        break\n",
    "        \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31f36c8",
   "metadata": {},
   "source": [
    "**Below is code of tracking with bounding box**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d85c5cb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "# easier to track color in HSV space\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# record video\n",
    "fourcc=cv.VideoWriter_fourcc(*'XVID')\n",
    "w = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv.VideoWriter('output.mp4',fourcc,20,(w,h))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    # Take each frame\n",
    "    ret, frame=cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "\n",
    "        # Convert BGR to HSV\n",
    "        hsv=cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "\n",
    "        #define range of color in HSV\n",
    "        lower_color=np.array([90-10,50,50]) \n",
    "        upper_color=np.array([90+10,255,255]) \n",
    "\n",
    "        #Threshold the HSV image to get only my color\n",
    "        mask = cv.inRange(hsv,lower_color, upper_color)\n",
    "\n",
    "        #operate on mask! get contour (already in grayscale) SARAH ADDED\n",
    "\n",
    "        # find canny edges\n",
    "        edged=cv.Canny(mask,30,200)\n",
    "\n",
    "        # Find contours\n",
    "        contours,hierarhcy=cv.findContours(edged,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_NONE)\n",
    "        cv.imshow('Canny Edges After Contouring', edged)\n",
    "        \n",
    "        if len(contours)==0:\n",
    "            continue\n",
    "        \n",
    "        # Draw Box\n",
    "        \n",
    "        for cnt in contours:\n",
    "            x,y,w,h = cv.boundingRect(cnt)\n",
    "            cv.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        \n",
    "        #Bitwise-AND mask and original image\n",
    "        res=cv.bitwise_and(frame,frame,mask=mask)\n",
    "        \n",
    "        # write out: frame, mask, res, edged\n",
    "        out.write(frame)\n",
    "        out.write(mask)\n",
    "        out.write(res)\n",
    "        out.write(edged)\n",
    "        \n",
    "        \n",
    "   \n",
    "\n",
    "        #finalRes=cv.bitwise_and()\n",
    "\n",
    "        cv.imshow('frame',frame)\n",
    "        cv.imshow('mask',mask)\n",
    "        cv.imshow('res',res)\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "# Release everything if the job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "        \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdbdf91",
   "metadata": {},
   "source": [
    "# References and Improvements\n",
    "I approached this problem by… \n",
    "1. Turning on the video camera capture using code referenced from:  https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html \n",
    "2. I converted the frame from BGR to HSV because it worked better for thresholding capture with code referenced from: https://docs.opencv.org/4.x/df/d9d/tutorial_py_colorspaces.html \n",
    "3. Next, I operated on the mask to find the contours using canny edges with code referenced from: https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html \n",
    "4. Then, I bitwise-AND mask and the original image together to form a video of my object being tracked by a contour using code referenced from: https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html \n",
    "5. Finally, I saved the recorded video using code referenced from: https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ede44f",
   "metadata": {},
   "source": [
    "### Problem 2: Lights off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7baaa70",
   "metadata": {},
   "source": [
    "When I turned my lights off, I could not track the object at all because my camera could not pick up the color of the object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e742f0c0",
   "metadata": {},
   "source": [
    "### Problem 3: different brightness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80afa331",
   "metadata": {},
   "source": [
    "I tried 3 different brightness\n",
    "1. All the way down: I could pick up the color about 50-70%\n",
    "2. Medium: I could pick up the color about 90%\n",
    "3. All the way up: I could not pick up the color at all. I think it is because once the brightness was all the way up, it was no longer the color that I had chosen to track. The brightness was beyond the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a8ba3",
   "metadata": {},
   "source": [
    "### Problem 4: find the dominant color in a central rectangle in my video feed\n",
    "- use k-means\n",
    "- use non-phone object and change the brightness of its surrounding\n",
    "- use phone and change the brightness\n",
    "- is the phone or the non-phone object more robust?\n",
    "\n",
    "Reference: https://code.likeagirl.io/finding-dominant-colour-on-an-image-b4e075f98097"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3deeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.2-cp39-cp39-macosx_10_9_x86_64.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /Users/sarah/opt/anaconda3/envs/ece180/lib/python3.9/site-packages (from scikit-learn) (1.23.1)\n",
      "Collecting joblib>=1.0.0\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting scipy>=1.3.2\n",
      "  Downloading scipy-1.9.1-cp39-cp39-macosx_12_0_universal2.macosx_10_9_x86_64.whl (58.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.1.2 scipy-1.9.1 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "774a3f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jw/c2wxwfxj1gd3nk4l01q2l9ww0000gn/T/ipykernel_80259/3713696325.py:70: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  clt.fit(frame)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAB2ElEQVR4nO3coQ3AMAwAwabq/iu7K4REAX+HDQxfBl4zMw8AkPXeXgAAuEsMAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQ9+0OrrVO7gEAHLDzW9BlAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxH27gzNzcg8A4BKXAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCI+wG4SgrJNILN+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACA0lEQVR4nO3YsWmCURhG4d+QHURILWQSF3COTCZkhKygtdg4gCtcR9Ai5gbO89Rf8ZaHbzXGGAsAkPU2ewAAMJcYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAg7v3Zw+vt8sod/EPn42n5OXzPngG/ar3dLJvPj9kz4M/sd18Pb3wGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABA3GqMMWaPAADm8RkAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgLg7lpcRxdRE0FAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACAElEQVR4nO3YoXFCURRF0f8yaQKVlIOIjWSGiYxJAXSK/7TxUgIYeGKvpa84cs8dc865AQBZb6sHAABriQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLeHz28/J6euQNeZoyxff2ct8Pnx+opLLDfrtu+X1fPgJf5Pv7dvfEZAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWPOOVePAADW8RkAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgLh/f0ARxc3mIQMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACB0lEQVR4nO3YwU1CURRF0Y+xB0Kcm1iJFViH1RiqoCUSGnDyQYePEnSgPJK91vgOznDnbsYYYwEAsh5mDwAA5hIDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEPf728PR5/M8d3JGvdV0OH/vl+3yZPQX+3PZ5t+xenmbPgJt5e33/8cZnAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxG3GGGP2CABgHp8BAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIi7AgjWFMUpUFjDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACCUlEQVR4nO3YPU2FQRRF0RlCBQ0iCCZwgACE4IUCD88RHQJoHj/lIAGaL0Oy16pvccqdO9daawAAWRe7BwAAe4kBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADiLv96+Pb+euQO/pGv83mcnl/G98fn7ilwiDnnuL2/G1c317unwOEeH55+vfEZAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcXOttXaPAAD28RkAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgLgf6OMUxTr23qIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACBklEQVR4nO3YsU2CURhG4R/jDAbtTVyFBRiEXUjcwZXs7G1QLC8jQAFekvM89Ve85cm3GmOMBQDIepg9AACYSwwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABD3eOnh1/fnLXdwR46Hw/Kxf1/+fn5nT4Gre3pdL89vL7NnwL/ZbnZnb3wGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABA3GqMMWaPAADm8RkAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgLgT9DsUxRufsg4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACB0lEQVR4nO3csU0DMBRFURsxQWoqRBUGyQZILMUgDMAGDIEyBFVqM0LSICPuObWLV179wnOttQYAkHW3ewAAsJcYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAg7v7Wh+8fb7+5A/6Ey/dlnD+/xvAXF//I4/NxnF5fxpxz9xQ2eDg8XX3jMgAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLmWmvtHgEA7OMyAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxP1DtE8VbAW8fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAABmCAYAAABWfZKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACBUlEQVR4nO3csW1CQRBAwePLGYnbgBZcngsgcmwJUlIkuoGINs4l4MT6Fm8m3mCj1dMFt5lzzgEAZC1rLwAArEsMAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQ9/bbwfP18Jd7wL+w3b6P/e5jLItOrnrc7uPyfRz+Y+NVfH6dns64eAAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIG4z55xrLwEArMfLAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADE/QAhQRTFskRSlgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m frame \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mreshape((frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;241m3\u001b[39m)) \u001b[38;5;66;03m#represent as row*column,channel number\u001b[39;00m\n\u001b[1;32m     69\u001b[0m clt \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m) \u001b[38;5;66;03m#cluster number\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m clt\u001b[38;5;241m.\u001b[39mfit(frame)\n\u001b[1;32m     72\u001b[0m hist \u001b[38;5;241m=\u001b[39m find_histogram(clt)\n\u001b[1;32m     73\u001b[0m bar \u001b[38;5;241m=\u001b[39m plot_colors2(hist, clt\u001b[38;5;241m.\u001b[39mcluster_centers_)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ece180/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1410\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1406\u001b[0m best_inertia, best_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_init):\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;66;03m# Initialize centers\u001b[39;00m\n\u001b[0;32m-> 1410\u001b[0m     centers_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_centroids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m   1414\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ece180/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:952\u001b[0m, in \u001b[0;36m_BaseKMeans._init_centroids\u001b[0;34m(self, X, x_squared_norms, init, random_state, init_size, n_centroids)\u001b[0m\n\u001b[1;32m    949\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk-means++\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 952\u001b[0m     centers, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_kmeans_plusplus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    959\u001b[0m     seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mpermutation(n_samples)[:n_clusters]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ece180/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:219\u001b[0m, in \u001b[0;36m_kmeans_plusplus\u001b[0;34m(X, n_clusters, x_squared_norms, random_state, n_local_trials)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_clusters):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# Choose center candidates by sampling with probability proportional\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# to the squared distance to the closest existing center\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     rand_vals \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39muniform(size\u001b[38;5;241m=\u001b[39mn_local_trials) \u001b[38;5;241m*\u001b[39m current_pot\n\u001b[0;32m--> 219\u001b[0m     candidate_ids \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msearchsorted(\u001b[43mstable_cumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosest_dist_sq\u001b[49m\u001b[43m)\u001b[49m, rand_vals)\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# XXX: numerical imprecision can result in a candidate_id out of range\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     np\u001b[38;5;241m.\u001b[39mclip(candidate_ids, \u001b[38;5;28;01mNone\u001b[39;00m, closest_dist_sq\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, out\u001b[38;5;241m=\u001b[39mcandidate_ids)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ece180/lib/python3.9/site-packages/sklearn/utils/extmath.py:1064\u001b[0m, in \u001b[0;36mstable_cumsum\u001b[0;34m(arr, axis, rtol, atol)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstable_cumsum\u001b[39m(arr, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-05\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-08\u001b[39m):\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;124;03m\"\"\"Use high precision for cumsum and check that final value matches sum.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m \n\u001b[1;32m   1052\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;124;03m        Absolute tolerance, see ``np.allclose``.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1064\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m     expected \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(arr, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(\n\u001b[1;32m   1067\u001b[0m         np\u001b[38;5;241m.\u001b[39misclose(\n\u001b[1;32m   1068\u001b[0m             out\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis), expected, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         )\n\u001b[1;32m   1070\u001b[0m     ):\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ece180/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2571\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(a, axis, dtype, out)\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_cumsum_dispatcher)\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcumsum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2499\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2500\u001b[0m \u001b[38;5;124;03m    Return the cumulative sum of the elements along a given axis.\u001b[39;00m\n\u001b[1;32m   2501\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2569\u001b[0m \n\u001b[1;32m   2570\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcumsum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ece180/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def find_histogram(clt):\n",
    "    \"\"\"\n",
    "    create a histogram with k clusters\n",
    "    :param: clt\n",
    "    :return:hist\n",
    "    \"\"\"\n",
    "    numLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(clt.labels_, bins=numLabels)\n",
    "\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "\n",
    "    return hist\n",
    "\n",
    "def plot_colors2(hist, centroids):\n",
    "    bar = np.zeros((50, 300, 3), dtype=\"uint8\")\n",
    "    startX = 0\n",
    "\n",
    "    for (percent, color) in zip(hist, centroids):\n",
    "        # plot the relative percentage of each cluster\n",
    "        endX = startX + (percent * 300)\n",
    "        cv2.rectangle(bar, (int(startX), 0), (int(endX), 50),\n",
    "                      color.astype(\"uint8\").tolist(), -1)\n",
    "        startX = endX\n",
    "\n",
    "    # return the bar chart\n",
    "    return bar\n",
    "\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame=cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        frame = frame.reshape((frame.shape[0] * frame.shape[1],3)) #represent as row*column,channel number\n",
    "        clt = KMeans(n_clusters=3) #cluster number\n",
    "        clt.fit(frame)\n",
    "\n",
    "        hist = find_histogram(clt)\n",
    "        bar = plot_colors2(hist, clt.cluster_centers_)\n",
    "\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(bar)\n",
    "        plt.show()\n",
    "        \n",
    "        cv.imshow('frame',frame)\n",
    "        \n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "# Release everything if the job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "        \n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
